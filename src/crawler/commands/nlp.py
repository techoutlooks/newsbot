from daily_query.helpers import mk_date
from newsutils.crawl import DayCmd
from newsutils.nlp import DayNlp
from newsutils.conf import METAPOST

from scrapy.commands import ScrapyCommand
from scrapy.exceptions import UsageError
from scrapy.utils.conf import arglist_to_dict

from daily_query.mongo import Collection
from newsutils.logging import log_running, NamespaceFormatter

# type of summary to generate/save, whether one per post, or
# a meta summary (summary of summaries) across all sibling posts.
CMD_VERBS = ('similarity', 'summary', METAPOST)


class NlpCmd(DayCmd):
    """
    Scrapy command that runs NLP-related tasks across several days.
    Cf. `newsutils.nlp.DayNlp.__doc__`

    Syntax:
    -------
         scrapy nlp \
          [-D from=<%Y-%m-%d> -D to=<%Y-%m-%d>] \
          [-d <%Y-%m-%d>] \
          [-t siblings=<%f>] [-t related=<%f>]

    Notes:
    ------
        (1) Detects existing processes: exits if another instance already runs.

    Usage:
    ------
        scrapy nlp [subtask] [thresholds] [dates]
        nlp subtask selection: `similarity|summary|metapost`

        # run all subtasks, with default thresholds, and various date selection options
        $ scrapy nlp                  # today's posts, runs all subtasks
        $ scrapy nlp -d 2021-08-28    # specific day, default thresholds
        $ scrapy nlp -d 2021-08-28 -d 2021-08-29  # date list

        # with specific thresholds (same date options apply)
        $ scrapy nlp -t siblings=0.4 -t related=0.2

        # only compute posts similarity (same date options apply)
        $ scrapy nlp similarity -t siblings=0.10 -t related=0.05 -D from=2022-05-20

        # only perform summarisation (same date options apply)
        $ scrapy nlp summary -t siblings=0.10 -t related=0.05 -D from=2022-05-20

        # only generate metaposts (same date options apply)
        $ scrapy nlp metapost -t siblings=0.10 -t related=0.05 -D from=2022-05-20


    TODO: try more sophisticated methods eg. LDA,
        instead of relying on newspaper3k/goose3 extractive summary (`summary` field).
    """

    # # whether to use the post extractive summary generated by newspaper3k/goose3
    # # instead of the post text, in all NLP tasks (summarization, categorization)
    # # `summary_as_text = False` yield better summaries in practice.
    # summary_as_text = False
    # meta_summary_uses_nlp = False

    # ScrapyCommand overrides
    requires_project = True

    def short_desc(self):
        return "Update day's (default, today) articles with similarity scores"

    def syntax(self):
        return f'<{"|".join(filter(None, CMD_VERBS))}> [options]'

    def add_options(self, parser):

        ScrapyCommand.add_options(self, parser)

        parser.add_argument(
            "-D", "--days", dest="days_range", action="append", default=[], metavar="NAME=VALUE",
            help="articles matching date range; eg. -D from=2022-03-19 [to=2022-04-22]."
                 "no option supplied defaults to today's articles.")
        parser.add_argument(
            "-d", "--day", dest="days_list", action="append", default=[], metavar="DAY",
            help=f"match post published on given days only; eg. `-d 2021-06-23. "
                 f"(default: -d {mk_date()})")
        parser.add_argument(
            "-t", "--threshold", dest="thresholds", action="append", default=[], metavar="NAME=VALUE",
            help=f"match posts past minimum threshold values only. (defaults: "
                 f" -t siblings={self.settings['POSTS']['similarity_siblings_threshold']})"
                 f" -t related={self.settings['POSTS']['similarity_related_threshold']})"
                 f" -t sumlen={self.settings['POSTS']['summary_minimum_length']})")

        # boolean flags
        parser.add_argument(
            "--nlp-uses-meta", dest="nlp_uses_meta", action="store_true",
            help=f"also add metaposts as inputs to NLP tasks?")
        parser.add_argument(
            "--nlp-uses-excerpt", dest="nlp_uses_excerpt", action="store_true",
            help=f"metaposts only: use text from `excerpt` instead of `text` field?")
        parser.add_argument(
            "--meta-uses-nlp", dest="meta_uses_nlp", action="store_true",
            help=f"metapost generation: use text from `caption` field instead of `title` field?; default is True")

        # TODO: add option parsing for `SIMILARITY_MAX_DOCS`
        #   cmd options override in `process_options`

    def process_options(self, args, opts):

        mkfloat = lambda v: float(v) if v else None
        mkint = lambda v: int(v) if v else None

        ScrapyCommand.process_options(self, args, opts)
        try:
            opts.days_range = arglist_to_dict(opts.days_range)
            opts.thresholds = arglist_to_dict(opts.thresholds)

        except ValueError as e:
            print(e)
            raise UsageError("Invalid -a value, use -a NAME=VALUE", print_help=False)

        # override project settings iff supplied by the cmdline
        # careful not to overwrite working defaults with undefined values from the cmdline
        params = dict(filter(lambda p: p[1], {
            "similarity_siblings_threshold": mkfloat(opts.thresholds.get(self.siblings_field)),
            "similarity_related_threshold": mkfloat(opts.thresholds.get(self.related_field)),
            "summary_minimum_length": mkint(opts.thresholds.get('sumlen')),
            "nlp_uses_meta": opts.nlp_uses_meta,
            "nlp_uses_excerpt": opts.nlp_uses_excerpt,
            "meta_uses_nlp": opts.meta_uses_nlp
        }.items()))

        self.set_post_settings(params)

    def run(self, args, opts):

        # perform all actions by default, ie., iff None,
        # ie., similarity -> summarisation -> metapost generation
        verb = args[0] if args else None
        assert verb in (*CMD_VERBS, None), \
            f"unsupported verb: {verb}. " \
            f"valid actions: {', '.join(CMD_VERBS)}"

        existed = self.is_running()
        if existed:
            self.log_task_ended("Exiting: instance [{pid}] already running:\n {cmdline}".format(
                pid=existed.pid, cmdline=existed.cmdline()))
            raise SystemExit(0)

        self.save(
            verb=verb,
            days={'days_from': opts.days_range.get('from'),
                  'days_to': opts.days_range.get('to'),
                  'days': opts.days_list}
        )

    def save(self, verb, days):
        """
        Computes and store articles similarity scores for given dates.
        :params day: str|date: the articles' date, eg. `2021-06-22`
        """

        stats = dict(
            total=0, saved=0, words=0,
            similarity=0, summary=0, metapost=0)

        fmt = NamespaceFormatter({"from": 'N/A', "to": 'N/A'})
        msg = fmt.format("`scrapy nlp` (docs from {days_from} to {days_to}) +{days}", **days)

        # ensure day correspond to an existing database collection
        collections, stats['total'] = self.daily.get_collections(**days)
        days_names = [str(d) for d in collections]
        for day in collections:

            # run per day
            # day_counts = self.save_day(day, verb)
            save_day = lambda cmd, *args, **kwargs: \
                cmd.save_day(*args, **kwargs)
            day_counts = log_running(f"nlp {verb or 'all'} {day}", msg) \
                (save_day)(self, day, verb)

            for s in list(stats):
                stats[s] += day_counts[s]

        self.log_task_ended(
            "saved ({saved}) fields in ({total}) docs, ({words}) words: "
            "generated (similarity/summary/metapost): {similarity}/{summary}/{metapost} posts. "
            f"published on: {days_names}.", **stats)

    def save_day(self, collection: Collection, verb: str):
        """ Perform NLP (similarity, title/text summary, metapost generation)
        and save the results to the database """

        nlp = DayNlp(collection)
        return nlp.save_day(verb)
